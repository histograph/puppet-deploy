#!/usr/bin/env bash

source $(dirname $0)/../utils/set-vars "${1}"

HIST_DATA_DIR="${SRC_HOME}/data"
HIST_IMPORT_DIR="${SRC_HOME}/import"

if [ "$(read_params  histograph data.doDownload) " == "true " ]
then
  echo "Download repos ${DATA_REP_TODOWNLOAD}"

  if [ "$(echo $DATA_REP_TODOWNLOAD | grep bag)" != "" ]
  then

    cd ${SRC_HOME}
    wget http://data.nlextract.nl/bag/postgis/bag-laatst.backup -O bag-laatst.backup.new

    if [ ! -f bag-laatst.backup -o bag-laatst.backup.new -nt bag-laatst.backup ]
    then
      service postgresql start
      mv bag-laatst.backup.new bag-laatst.backup
      su postgres -c "psql" < $(dirname $0)/../utils/bag.sql
      su postgres -c "pg_restore --jobs 4 --dbname=bag --exit-on-error bag-laatst.backup"
      FILTERED_DATA_REP_TODOWNLOAD="${DATA_REP_TODOWNLOAD}"
    else
      FILTERED_DATA_REP_TODOWNLOAD="$(echo ${DATA_REP_TODOWNLOAD} | sed 's/\(.*\)bag\(.*\)/\1\2/g')"
    fi
  fi

  cd ${HIST_DATA_DIR}
  sudo su $MYUSER -c "node index.js --config ${SRC_HOME}/config.yaml ${FILTERED_DATA_REP_TODOWNLOAD}"

  service postgresql stop
fi

# The fact to leave the bag repo in the list of repositories DATA_REP_TODOWNLOAD,
# even though the current version might be already up to date,
# is based on the belief that import will not import it if the dataset is not different from the imported one,
# and this solution is more resilient in case of an earlier failed import

if [ "$(read_params  histograph data.doImport) " == "true " ]
then
  cd ${HIST_IMPORT_DIR}
  THE_REPOS="${DATA_REP_ONDISK} ${DATA_REP_TODOWNLOAD} ${EL_DATA_REP}"
  echo "Import repos ${THE_REPOS}"
  sudo su $MYUSER -c "node index.js --config ${SRC_HOME}/config.yaml --force ${THE_REPOS}"
fi
